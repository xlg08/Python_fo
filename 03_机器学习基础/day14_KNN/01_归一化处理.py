'''
    演示  特征预处理之归一化
        特征预处理解释：
            背景：
                在实际开发中，如果多个特征列因为量纲(单位)的问题,导致数值的差距过大。
                则会导致模型预测值偏差。
                为了保证每个列对最终的预测结果的权重比都是相近的。
                所以需要对特征预处理操作。
            特征预处理实现方式;
                1.归一化（现在）
                2.标准化
            归一化介绍：
                概述：是特征预处理一种方案
                    对原始数据进行处理，获取1个，默认[mi, mx]      [0, 1] 区间值
                公式：     (min max 列的     mx  mi区间的)
                    x' = (x - min) / (max - min)
                    x'' = x' * (mx - mi) + mi
                公式解释：
                    x --> 某一个特征列的值：原值
                    min --> 该特征列的最小值
                    max --> 该特征列的最大值
                    mi  --> 区间的最小值默认 0
                    mx  --> 区间的最大值默认 1
                弊端：
                    强依赖于该列的特征  最大值和最小值，如果差值比较大的话，计算效果不明显
                    归一化适用于小数据集 的特征预处理。
'''
# 1.导包
from sklearn.preprocessing import MinMaxScaler  # 归一化的类

# 2.准备特征数据      每个子列表 = 1个样本
data = [[90, 2, 10, 40], [60, 4, 15, 45], [75, 3, 13, 46]]

# 3.创建归一化对象，    feature_range = 设置区间值       默认[0,1]     包头包尾
transfer = MinMaxScaler(feature_range=(0, 1))

# 4.具体的归一化操作，对数据进行归一化
new_data = transfer.fit_transform(data)
# 本质上是执行了下面两句话
# fit_transform本质上是父类基类的抽象方法
#   底层执行子类的 fit() 和 transform() 方法
# fit() 是子类方法
# transfer.fit()            # 计算用于后续扩展的最小值和最大值
# transfer.transform()

# 5.显示归一化结果
print(f"归一化后的数据集：\n{new_data}")
